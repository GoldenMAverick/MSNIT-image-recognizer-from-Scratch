
# ğŸ§  Digit Recognizer using Neural Network from Scratch

This repository implements a handwritten digit recognizer built entirely from scratch using NumPy. It trains on the [MNIST digit dataset](https://www.kaggle.com/competitions/digit-recognizer/) and predicts digits 0â€“9 from 28x28 grayscale images, without using any high-level deep learning libraries like TensorFlow or PyTorch.

---

## ğŸ” Overview

- **Architecture:** 2-layer fully connected neural network
- **Input Layer:** 784 units (28x28 pixels flattened)
- **Hidden Layer:** 10 units with ReLU activation
- **Output Layer:** 10 units with Softmax activation (for digit classes 0â€“9)
- **Loss Function:** Cross-entropy
- **Optimizer:** Gradient Descent

---

## ğŸ§® Mathematical Formulation

### ğŸ” Forward Propagation

![Forward Propagation](./images/Screenshot_2025-06-16_174841.png)

### ğŸ”„ Backward Propagation & Parameter Updates

Follows standard backpropagation with partial derivatives for updating weights and biases using the gradients of loss w.r.t each parameter.

---

## ğŸ“ Variable Shapes

Shapes for all major variables in forward and backward propagation:

![Variable Shapes](./images/Screenshot_2025-06-16_174852.png)

---

## ğŸ“‚ Dataset

This uses the [Kaggle Digit Recognizer dataset](https://www.kaggle.com/competitions/digit-recognizer/):

- Each example is a 28x28 pixel grayscale image.
- Labels are digits `0â€“9`.
- Dataset is pre-split into training and dev sets.

---

## ğŸ§° Project Structure

```
.
â”œâ”€â”€ digit_recognizer.py     # All logic for model, training, testing
â”œâ”€â”€ train.csv               # Dataset (from Kaggle)
â”œâ”€â”€ images/                 # Diagrams for forward/backward propagation
â”‚   â”œâ”€â”€ Screenshot_2025-06-16_174841.png
â”‚   â””â”€â”€ Screenshot_2025-06-16_174852.png
â”œâ”€â”€ README.md               # This file
```

---

## ğŸš€ How to Run

1. Download the dataset from [Kaggle](https://www.kaggle.com/competitions/digit-recognizer/).
2. Place `train.csv` in the same directory as the code.
3. Run the training and prediction:
```bash
python digit_recognizer.py
```

---

## ğŸ§ª Sample Predictions

Test individual digits using:
```python
test_prediction(index, W1, b1, W2, b2)
```

Youâ€™ll get the prediction, label, and a visual of the digit image.

---

## âœï¸ Implementation Details

- Manual matrix multiplication (no `Dense` layers)
- One-hot encoding for labels
- ReLU and Softmax activation functions
- Gradient descent with fixed learning rate
- Modular code: separate functions for forward, backward, update, and prediction

---

## ğŸ“Š Performance

The model achieves decent accuracy (~85â€“90%) on MNIST with just 500 iterations and basic architecture.

---

## ğŸ“Œ TODO

- Add cross-validation
- Add regularization (L2, dropout)
- Visualize loss over epochs
- Save/load model parameters

---

## ğŸ§  Concepts Used

- Neural networks
- Activation functions
- Backpropagation
- Chain rule of derivatives
- One-hot encoding
- Numpy broadcasting

---



---

Feel free to fork or contribute to make it even better!
